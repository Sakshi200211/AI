{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce3b3d24-a991-4eec-8d1d-8f4454e7359a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8662b945-33e3-4d3d-bb64-80a4d487472a",
   "metadata": {},
   "source": [
    "# image read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff3be5a4-9233-4af9-a0c2-23acc00741aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"animal.jpg\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f058863e-8a19-45cc-b053-b44099689531",
   "metadata": {},
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a8c948-beee-4f08-bc10-46169dbb162a",
   "metadata": {},
   "source": [
    "# Image Show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e35bece9-e2e4-4807-85e9-153ee06872ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow(\"Original Image\" ,img)\n",
    "cv.waitKey(0) # waitkey is so that loaded image stays on screen\n",
    "cv.destroyAllWindows() # we have Close this imaage or prograam will not goforward\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b90815-aa40-42f5-9cf9-1ee52b57ea95",
   "metadata": {},
   "source": [
    "# Image Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15d9aa4b-bb70-4f98-bd54-8968ef7ff2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_img = cv.resize(img,(200,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43c67c1b-6915-4212-af1b-66bd4be591c0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[231, 180,   0],\n",
       "        [231, 180,   0],\n",
       "        [231, 180,   0],\n",
       "        ...,\n",
       "        [231, 180,   0],\n",
       "        [231, 180,   0],\n",
       "        [231, 180,   0]],\n",
       "\n",
       "       [[231, 180,   0],\n",
       "        [231, 180,   0],\n",
       "        [231, 180,   0],\n",
       "        ...,\n",
       "        [231, 180,   0],\n",
       "        [231, 180,   0],\n",
       "        [231, 180,   0]],\n",
       "\n",
       "       [[231, 180,   0],\n",
       "        [231, 180,   0],\n",
       "        [231, 180,   0],\n",
       "        ...,\n",
       "        [231, 180,   0],\n",
       "        [231, 180,   0],\n",
       "        [231, 180,   0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 80, 184, 155],\n",
       "        [ 81, 184, 156],\n",
       "        [ 81, 184, 156],\n",
       "        ...,\n",
       "        [115, 212, 198],\n",
       "        [115, 212, 198],\n",
       "        [116, 212, 199]],\n",
       "\n",
       "       [[ 81, 184, 149],\n",
       "        [ 81, 183, 149],\n",
       "        [ 81, 183, 149],\n",
       "        ...,\n",
       "        [115, 212, 198],\n",
       "        [115, 212, 198],\n",
       "        [115, 212, 198]],\n",
       "\n",
       "       [[ 83, 184, 153],\n",
       "        [ 85, 186, 154],\n",
       "        [ 87, 188, 159],\n",
       "        ...,\n",
       "        [107, 205, 186],\n",
       "        [109, 207, 189],\n",
       "        [115, 211, 199]]], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7eb35728-2040-4db1-b173-dbbb115ab612",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imwrite(r\"D:\\Data Science notes\\AI\\image Augmentation\\resized_img.jpg\",re_img)\n",
    "cv.imshow(\"Resized Image\" ,re_img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffdb5fa-d2cc-489d-b0f2-13a16891b465",
   "metadata": {},
   "source": [
    "# Image Color Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25ae6c42-3de9-4241-a5fc-b7db9beac5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "red=re_img.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a39f905b-734f-4e69-befc-901c9d677651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60ae150e-1583-47fb-8b65-f65919f8b8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "red[:,:,[0,1]] =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2510d520-da9c-489d-b387-3fadb4e7fbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imwrite(r\"D:\\Data Science notes\\AI\\image Augmentation\\red_img.jpg\",red)\n",
    "cv.imshow(\"Resized Image\" ,red)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a532448-12b8-43fe-8c81-fdcf53f3cccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "green = re_img.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15707fcb-db2e-4503-b0bb-49c46d310330",
   "metadata": {},
   "outputs": [],
   "source": [
    "green[:,:,[0,2]] =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d303a741-1ceb-45ed-acda-1c678ede87f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imwrite(r\"D:\\Data Science notes\\AI\\image Augmentation\\green.jpg\",green)\n",
    "cv.imshow(\"Resized Image\" ,green)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ed8519f-f216-4e39-a91a-ff7a52020cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "blue = re_img.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab71ce97-84a0-4078-b000-fd217ce2c3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "blue[:,:,[1,2]] =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b1930479-869f-44c1-982e-0f145b4276dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imwrite(r\"D:\\Data Science notes\\AI\\image Augmentation\\bllue.jpg\",blue)\n",
    "cv.imshow(\"Resized Image\" ,blue)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a65ab028-814f-4135-8d8b-971d1b1e6b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow(\"Addition of all color channel\" ,(blue+green+red))\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7bba711f-2e52-484f-a5d8-ea859db14846",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.randint(0, 255,36).reshape(3,4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66964b83-067a-4ea8-be33-be7a569baf75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6dcc060-a052-4a6c-b174-782910148c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0,   0, 163],\n",
       "        [  0,   0,  90],\n",
       "        [  0,   0, 180],\n",
       "        [  0,   0, 106]],\n",
       "\n",
       "       [[  0,   0,  59],\n",
       "        [  0,   0, 242],\n",
       "        [  0,   0, 244],\n",
       "        [  0,   0,  21]],\n",
       "\n",
       "       [[  0,   0, 199],\n",
       "        [  0,   0, 168],\n",
       "        [  0,   0,  74],\n",
       "        [  0,   0, 201]]], dtype=int32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[:,:,[0,1]] =0\n",
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ac8755-53f7-44a1-8739-28e83e91e984",
   "metadata": {},
   "source": [
    "# Image color to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "278979bf-826b-4e7e-b73a-afe20906f6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_img = cv.cvtColor(re_img ,cv.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "39fd7412-bfac-476f-82b3-105a6d1c51a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imwrite(r\"D:\\Data Science notes\\AI\\image Augmentation\\gray_img.jpg\",gray_img)\n",
    "cv.imshow(\"Gray Image\" ,gray_img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393f4e73-bd52-4f18-9257-8d23e181673b",
   "metadata": {},
   "source": [
    "# Adding Blur to Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25d5df89-baab-4ee0-8d97-2cefc499d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_img1= cv.GaussianBlur(re_img ,(3,3),2) #(5,5)kernel should be always odd\n",
    "blur_img2= cv.GaussianBlur(re_img ,(5,5),6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0940947f-087a-4c27-9d09-609615a23eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_img = np.hstack((blur_img1,blur_img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a0c7c0a8-9c02-41d6-a91c-2eb878194cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imwrite(r\"D:\\Data Science notes\\AI\\image Augmentation\\blur_imgs.jpg\",two_img)\n",
    "cv.imshow(\"Blur Images\" ,two_img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d931a56-7722-43b1-8a95-e313ec95f6a8",
   "metadata": {},
   "source": [
    "# Edge Detection in Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9274963b-da96-4b26-93b9-94c24d7aa7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges1 = cv.Canny(gray_img,100,200)\n",
    "edges2 = cv.Canny(gray_img,150,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "447821f7-c2f7-4ff4-b4ff-1dfe2a4dcc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_edges = np.hstack((edges1,edges2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "be53aa49-84eb-46a0-9eff-edb57628c8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imwrite(r\"D:\\Data Science notes\\AI\\image Augmentation\\two_edges_imgs.jpg\",two_edges)\n",
    "cv.imshow(\"Edges of Images\" ,two_edges)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b95e849-8448-4bc1-a241-9673692d34b8",
   "metadata": {},
   "source": [
    "# Rotate Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e092e0f9-daa4-44bb-ab2c-acf2f2319bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "angle =60\n",
    "rows ,cols = re_img.shape[:2] # rows means widhts ,cols means height\n",
    "center = (cols//2,rows//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6d7919c7-7fef-4c1b-b939-77261d798431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6774c57-defc-4d5c-97c0-570cbaa53f5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m rotate_mat \u001b[38;5;241m=\u001b[39m \u001b[43mcv\u001b[49m\u001b[38;5;241m.\u001b[39mgetRotationMatrix2D(center ,angle ,scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv' is not defined"
     ]
    }
   ],
   "source": [
    "rotate_mat = cv.getRotationMatrix2D(center ,angle ,scale=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2ef1f8b3-6209-4a04-94d9-709a162c41fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotate_img = cv.warpAffine(re_img,rotate_mat,(cols,rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6eaf919e-778d-4c8d-896b-e4d2e8a649a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imwrite(r\"D:\\Data Science notes\\AI\\image Augmentation\\rotated_img.jpg\",rotate_img)\n",
    "cv.imshow(\"Rotated Image\" ,rotate_img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4960035d-56aa-4c55-8d9c-00c27b450527",
   "metadata": {},
   "source": [
    "# Flipping Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f2a8fc95-c0ea-4074-875d-030aa696dd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "flip_vert =cv.flip(re_img,0)\n",
    "flip_hori =cv.flip(re_img,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8b0d4170-cd3a-4869-a0db-86b40f294e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_flip = np.hstack((flip_vert,flip_hori))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d3508f3b-309e-4ef0-98a0-dd0772330e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imwrite(r\"D:\\Data Science notes\\AI\\image Augmentation\\flipped_imgs.jpg\",two_flip)\n",
    "cv.imshow(\"Rotated Image\" ,rotate_img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef93c7d-ddab-4470-bbd1-024be2007ebb",
   "metadata": {},
   "source": [
    "# Shearing the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f4234c22-acdd-48e0-ab88-bfc0af00ec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shear_factor = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2e05a8e3-dc1c-456e-ba3d-28d31f6ce5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "shear_mat = np.float32([[1,shear_factor ,0],[0,1,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ccc420bd-39e6-4f21-a10d-2920a4124708",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheared_img  =cv.warpAffine(re_img ,shear_mat, (cols + int(shear_factor*rows),rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d1344527-3a54-4b8c-b355-62342a159ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imwrite(r\"D:\\Data Science notes\\AI\\image Augmentation\\skewed_img.jpg\",sheared_img)\n",
    "cv.imshow(\"Sheared Image\" ,sheared_img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51704adf-333f-47ce-90bb-ae94a94ea773",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
